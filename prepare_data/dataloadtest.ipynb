{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ae527a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries \n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb98a839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'categories', 'images', 'annotations'])\n"
     ]
    }
   ],
   "source": [
    "def json_loader():\n",
    "    \"\"\"\n",
    "    Load a COCO-style JSON file and convert it into a Python dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: The content of the JSON file as a Python dictionary.\n",
    "    \"\"\"\n",
    "    # Open the JSON file in read mode\n",
    "    with open('../dataset/data/_annotations.coco.json', 'r') as f:\n",
    "        # Parse the JSON file and convert it to a Python dictionary\n",
    "        data = json.load(f)\n",
    "        return data\n",
    "\n",
    "# Call the function to load JSON data\n",
    "new_data = json_loader()\n",
    "\n",
    "# Print the top-level keys of the JSON dictionary\n",
    "print(new_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a35b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>supercategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>wildfire</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fire</td>\n",
       "      <td>wildfire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      name supercategory\n",
       "0   0  wildfire          none\n",
       "1   1      fire      wildfire"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Images DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>license</th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6e1qges001kgk555z158f33_2_FALSE_COLOR_jpg.rf...</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6e1qges001kgk555z158f33_2_FALSE_CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6kgm9qr002yc455g5qs87kz_2_FALSE_COLOR_jpg.rf...</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6kgm9qr002yc455g5qs87kz_2_FALSE_CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6odzs5e002oao55heuig0a6_1_TRUE_COLOR_jpg.rf....</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6odzs5e002oao55heuig0a6_1_TRUE_COL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6b6pieh007rl455fwvb73gr_1_TRUE_COLOR_jpg.rf....</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6b6pieh007rl455fwvb73gr_1_TRUE_COL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6b5k38g003zl455bgtd1317_4_FALSE_COLOR__URBAN...</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6b5k38g003zl455bgtd1317_4_FALSE_CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6b5yjxa005nl45516k465kb_1_TRUE_COLOR_jpg.rf....</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6b5yjxa005nl45516k465kb_1_TRUE_COL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6opv5oo007xao553de9g7wd_2_FALSE_COLOR_jpg.rf...</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6opv5oo007xao553de9g7wd_2_FALSE_CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6cteplg00hkl4551scr5fko_1_TRUE_COLOR_jpg.rf....</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6cteplg00hkl4551scr5fko_1_TRUE_COL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6b652mi0068l4552keu9loj_6_SWIR_jpg.rf.113908...</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6b652mi0068l4552keu9loj_6_SWIR.jpg'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>cl6kjhhl5001h8w55fo1v1vqs_1_TRUE_COLOR_jpg.rf....</td>\n",
       "      <td>860</td>\n",
       "      <td>1200</td>\n",
       "      <td>2025-09-14T12:06:19+00:00</td>\n",
       "      <td>{'name': 'cl6kjhhl5001h8w55fo1v1vqs_1_TRUE_COL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  license                                          file_name  height  \\\n",
       "0      0        1  cl6e1qges001kgk555z158f33_2_FALSE_COLOR_jpg.rf...     860   \n",
       "1      1        1  cl6kgm9qr002yc455g5qs87kz_2_FALSE_COLOR_jpg.rf...     860   \n",
       "2      2        1  cl6odzs5e002oao55heuig0a6_1_TRUE_COLOR_jpg.rf....     860   \n",
       "3      3        1  cl6b6pieh007rl455fwvb73gr_1_TRUE_COLOR_jpg.rf....     860   \n",
       "4      4        1  cl6b5k38g003zl455bgtd1317_4_FALSE_COLOR__URBAN...     860   \n",
       "..   ...      ...                                                ...     ...   \n",
       "495  495        1  cl6b5yjxa005nl45516k465kb_1_TRUE_COLOR_jpg.rf....     860   \n",
       "496  496        1  cl6opv5oo007xao553de9g7wd_2_FALSE_COLOR_jpg.rf...     860   \n",
       "497  497        1  cl6cteplg00hkl4551scr5fko_1_TRUE_COLOR_jpg.rf....     860   \n",
       "498  498        1  cl6b652mi0068l4552keu9loj_6_SWIR_jpg.rf.113908...     860   \n",
       "499  499        1  cl6kjhhl5001h8w55fo1v1vqs_1_TRUE_COLOR_jpg.rf....     860   \n",
       "\n",
       "     width              date_captured  \\\n",
       "0     1200  2025-09-14T12:06:19+00:00   \n",
       "1     1200  2025-09-14T12:06:19+00:00   \n",
       "2     1200  2025-09-14T12:06:19+00:00   \n",
       "3     1200  2025-09-14T12:06:19+00:00   \n",
       "4     1200  2025-09-14T12:06:19+00:00   \n",
       "..     ...                        ...   \n",
       "495   1200  2025-09-14T12:06:19+00:00   \n",
       "496   1200  2025-09-14T12:06:19+00:00   \n",
       "497   1200  2025-09-14T12:06:19+00:00   \n",
       "498   1200  2025-09-14T12:06:19+00:00   \n",
       "499   1200  2025-09-14T12:06:19+00:00   \n",
       "\n",
       "                                                 extra  \n",
       "0    {'name': 'cl6e1qges001kgk555z158f33_2_FALSE_CO...  \n",
       "1    {'name': 'cl6kgm9qr002yc455g5qs87kz_2_FALSE_CO...  \n",
       "2    {'name': 'cl6odzs5e002oao55heuig0a6_1_TRUE_COL...  \n",
       "3    {'name': 'cl6b6pieh007rl455fwvb73gr_1_TRUE_COL...  \n",
       "4    {'name': 'cl6b5k38g003zl455bgtd1317_4_FALSE_CO...  \n",
       "..                                                 ...  \n",
       "495  {'name': 'cl6b5yjxa005nl45516k465kb_1_TRUE_COL...  \n",
       "496  {'name': 'cl6opv5oo007xao553de9g7wd_2_FALSE_CO...  \n",
       "497  {'name': 'cl6cteplg00hkl4551scr5fko_1_TRUE_COL...  \n",
       "498   {'name': 'cl6b652mi0068l4552keu9loj_6_SWIR.jpg'}  \n",
       "499  {'name': 'cl6kjhhl5001h8w55fo1v1vqs_1_TRUE_COL...  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Annotations DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>area</th>\n",
       "      <th>segmentation</th>\n",
       "      <th>iscrowd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[277, 207, 568.95, 591.79]</td>\n",
       "      <td>336698.921</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[800, 0, 157.45, 413.38]</td>\n",
       "      <td>65086.681</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[1062, 96, 58.37, 63.91]</td>\n",
       "      <td>3730.427</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[452, 442, 410.09, 350.6]</td>\n",
       "      <td>143777.554</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 163, 336.16, 375.08]</td>\n",
       "      <td>126086.893</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>954</td>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>[80, 30, 416.05, 183.75]</td>\n",
       "      <td>76449.188</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>955</td>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 345, 140.33, 146.25]</td>\n",
       "      <td>20523.263</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>956</td>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "      <td>[389, 361, 333, 340.52]</td>\n",
       "      <td>113393.160</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>957</td>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "      <td>[510, 270, 222.6, 245.95]</td>\n",
       "      <td>54748.470</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>958</td>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>[645, 519, 87.51, 126.38]</td>\n",
       "      <td>11059.514</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>959 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  image_id  category_id                        bbox        area  \\\n",
       "0      0         1            1  [277, 207, 568.95, 591.79]  336698.921   \n",
       "1      1         2            1    [800, 0, 157.45, 413.38]   65086.681   \n",
       "2      2         2            1    [1062, 96, 58.37, 63.91]    3730.427   \n",
       "3      3         2            1   [452, 442, 410.09, 350.6]  143777.554   \n",
       "4      4         2            1    [0, 163, 336.16, 375.08]  126086.893   \n",
       "..   ...       ...          ...                         ...         ...   \n",
       "954  954       496            1    [80, 30, 416.05, 183.75]   76449.188   \n",
       "955  955       496            1    [0, 345, 140.33, 146.25]   20523.263   \n",
       "956  956       497            1     [389, 361, 333, 340.52]  113393.160   \n",
       "957  957       498            1   [510, 270, 222.6, 245.95]   54748.470   \n",
       "958  958       499            1   [645, 519, 87.51, 126.38]   11059.514   \n",
       "\n",
       "    segmentation  iscrowd  \n",
       "0             []        0  \n",
       "1             []        0  \n",
       "2             []        0  \n",
       "3             []        0  \n",
       "4             []        0  \n",
       "..           ...      ...  \n",
       "954           []        0  \n",
       "955           []        0  \n",
       "956           []        0  \n",
       "957           []        0  \n",
       "958           []        0  \n",
       "\n",
       "[959 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def json_df(json_data):\n",
    "    \"\"\"\n",
    "    Convert COCO-style JSON data into three Pandas DataFrames: categories, images, and annotations.\n",
    "\n",
    "    Args:\n",
    "        json_data (dict): JSON data loaded from a COCO-style annotation file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three DataFrames in the order:\n",
    "            - df_categories: DataFrame of categories\n",
    "            - df_images: DataFrame of images\n",
    "            - df_annotations: DataFrame of annotations\n",
    "    \"\"\"\n",
    "    # using keys: ['info', 'licenses', 'categories', 'images', 'annotations']\n",
    "    # Convert the 'categories' section into a DataFrame\n",
    "    df_categories = pd.DataFrame(json_data['categories'])\n",
    "\n",
    "    # Convert the 'images' section into a DataFrame\n",
    "    df_images = pd.DataFrame(json_data['images'])\n",
    "\n",
    "    # Convert the 'annotations' section into a DataFrame\n",
    "    df_annotations = pd.DataFrame(json_data['annotations'])\n",
    "\n",
    "    return df_categories, df_images, df_annotations\n",
    "\n",
    "# Call the function to convert JSON data into DataFrames\n",
    "df_categories, df_images, df_annotations = json_df(new_data)\n",
    "\n",
    "# Preview the DataFrames\n",
    "print(\"Categories DataFrame:\")\n",
    "display(df_categories)\n",
    "\n",
    "print(\"\\nImages DataFrame:\")\n",
    "display(df_images)\n",
    "\n",
    "print(\"\\nAnnotations DataFrame:\")\n",
    "display(df_annotations)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41654ca4",
   "metadata": {},
   "source": [
    "##                                      2-A Exploration & nettoyage des donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79223371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values in Annotations DataFrame\n",
      "No NaN values in Images DataFrame\n",
      "No NaN values in Categories DataFrame\n"
     ]
    }
   ],
   "source": [
    "def check_nan(df):\n",
    "    \"\"\"\n",
    "    Check for missing values (NaN) in a DataFrame and return only the columns with at least one NaN.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to check for missing values.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A series containing only the columns with NaN values and their counts.\n",
    "    \"\"\"\n",
    "    # Count NaN values per column\n",
    "    nan_counts = df.isna().sum()\n",
    "    \n",
    "    # Filter only columns where NaN count > 0\n",
    "    nan_columns = nan_counts[nan_counts > 0]\n",
    "    \n",
    "    return nan_columns\n",
    "\n",
    "#  usage\n",
    "clean_anno = check_nan(df_annotations)\n",
    "clean_images = check_nan(df_images)\n",
    "clean_categ = check_nan(df_categories)\n",
    "\n",
    "# Only print the result if it contains data, for a cleaner output\n",
    "\n",
    "\n",
    "# Annotations DataFrame\n",
    "if not clean_anno.empty:\n",
    "    print(\"Annotations NaN columns:\")\n",
    "    print(clean_anno)\n",
    "else:\n",
    "    print(\"No NaN values in Annotations DataFrame\")\n",
    "    \n",
    "    \n",
    "# Images DataFrame\n",
    "if not clean_images.empty:\n",
    "    print(\"Images NaN columns:\")\n",
    "    print(clean_images)\n",
    "else:\n",
    "    print(\"No NaN values in Images DataFrame\")\n",
    "    \n",
    "    \n",
    "# Categories DataFrame\n",
    "if not clean_categ.empty:\n",
    "    print(\"Categories NaN columns:\")\n",
    "    print(clean_categ)\n",
    "else:\n",
    "    print(\"No NaN values in Categories DataFrame\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ba806d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 500\n",
      "Total number of annotations: 959\n"
     ]
    }
   ],
   "source": [
    "def total_number(df):\n",
    "    \"\"\"\n",
    "    Calculate the total number of rows in a DataFrame.\n",
    "\n",
    "    This can be used to count the total number of images or annotations,\n",
    "    depending on which DataFrame we pass.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to count rows from.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of rows in the DataFrame.\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    return total\n",
    "\n",
    "num_images = total_number(df_images)\n",
    "print(f\"Total number of images: {num_images}\")\n",
    "\n",
    "num_annotations = total_number(df_annotations)\n",
    "print(f\"Total number of annotations: {num_annotations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4410e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category names:\n",
      "['wildfire', 'fire']\n"
     ]
    }
   ],
   "source": [
    "def categories_names(df):\n",
    "    \"\"\"\n",
    "    Return a list of category names from a categories DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the 'name' column for categories.\n",
    "\n",
    "    Returns:\n",
    "        list: List of category names.\n",
    "    \"\"\"\n",
    "    category_name = df['name'].tolist()\n",
    "    return category_name\n",
    "\n",
    "category_list = categories_names(df_categories)\n",
    "print(\"Category names:\")\n",
    "print(category_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51f0fe87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "fire    493\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def images_per_category(df_annotations, df_categories):\n",
    "    \"\"\"\n",
    "    Calculate the number of unique images per category.\n",
    "\n",
    "    Args:\n",
    "        df_annotations (pd.DataFrame): DataFrame containing 'image_id' and 'category_id'.\n",
    "        df_categories (pd.DataFrame): DataFrame containing 'id' and 'name' for categories.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Number of unique images per category.\n",
    "    \"\"\"\n",
    "    # Merge annotations with categories\n",
    "    merged = df_annotations.merge(df_categories, left_on='category_id', right_on='id')\n",
    "    #display(merged)\n",
    "    # Drop duplicate image-category pairs\n",
    "    unique_images = merged[['image_id', 'name']].drop_duplicates()\n",
    "    \n",
    "    # Count images per category\n",
    "    count_per_category = unique_images.groupby('name').size()\n",
    "    return count_per_category\n",
    "\n",
    "# Example usage\n",
    "images_count = images_per_category(df_annotations, df_categories)\n",
    "print(images_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9a6107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations per image (preview):\n",
      "image_id\n",
      "1    1\n",
      "2    4\n",
      "3    1\n",
      "4    1\n",
      "5    2\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics of annotations per image:\n",
      "count    493.000000\n",
      "mean       1.945233\n",
      "std        1.405218\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        2.000000\n",
      "max       10.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def annotations_statistics(df_annotations):\n",
    "    \"\"\"\n",
    "    Compute the number of annotations per image and provide summary statistics.\n",
    "\n",
    "    Args:\n",
    "        df_annotations (pd.DataFrame): DataFrame containing annotations with a column 'image_id'.\n",
    "\n",
    "    Returns:\n",
    "        \n",
    "            - annotations_per_image (pd.Series): Number of annotations for each image.\n",
    "            - stats (pd.Series): Summary statistics of annotations per image (count, mean, min, max, quartiles).\n",
    "    \"\"\"\n",
    "    # Count the number of annotations per image\n",
    "    annotations_per_image = df_annotations.groupby('image_id').size()\n",
    "\n",
    "    # Compute summary statistics\n",
    "    stats = annotations_per_image.describe()\n",
    "\n",
    "    return annotations_per_image, stats\n",
    "\n",
    "\n",
    "# Example usage\n",
    "annotations_per_image, stats = annotations_statistics(df_annotations)\n",
    "\n",
    "print(\"Number of annotations per image (preview):\")\n",
    "print(annotations_per_image.head())\n",
    "\n",
    "print(\"\\nSummary statistics of annotations per image:\")\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb8c07",
   "metadata": {},
   "source": [
    "##                          2-b V√©rification des incoh√©rences dans les donn√©es \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d02a04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'': 1})\n"
     ]
    }
   ],
   "source": [
    "def cntr(folder_path):\n",
    "    \"\"\"\n",
    "    Count file extensions in a folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder.\n",
    "\n",
    "    Returns:\n",
    "        Counter: Counts of each file extension in the folder.\n",
    "    \"\"\"\n",
    "    # p = Path(folder_path)\n",
    "    # exts_list = []\n",
    "\n",
    "    # # Loop over each file in the folder\n",
    "    \n",
    "    # for f in p.iterdir():\n",
    "    #     if f.is_file():  # Only process files\n",
    "    #         ext = f.suffix.lower().lstrip('.')  # Get extension without dot\n",
    "    #         exts_list.append(ext)\n",
    "\n",
    "    # # Count how many times each extension appears\n",
    "    # return Counter(exts_list)\n",
    "    \n",
    "    p = Path(folder_path)\n",
    "    exts = [f.suffix.lower().lstrip('.') for f in p.iterdir() if f.is_file()]\n",
    "    return Counter(exts)\n",
    "\n",
    "exts = cntr(\"../dataset\")   \n",
    "print(exts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b6cab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = Path(\"../dataset\")\n",
    "# n_names = []\n",
    "# for n in p.iterdir(): \n",
    "#     if n.is_file():\n",
    "#         n_names.append(n.name)\n",
    "#     else:\n",
    "#         # i can delete this part to make the code more flixible \n",
    "#         raise FileNotFoundError(f\" file {n} is not exist\")        \n",
    "# # display(n_names)\n",
    "# img_names = df_images['file_name'].to_list()\n",
    "# # print(\"@\" * 50)\n",
    "# # display(img_names)\n",
    "\n",
    "# folder_images = set(n_names)\n",
    "# names_list = set(img_names)\n",
    "\n",
    "# missing_image_folder = names_list - folder_images\n",
    "# print(missing_image_folder)\n",
    "\n",
    "# missing_in_json = folder_images - names_list\n",
    "# print(missing_in_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "425f33eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in DataFrame but not in folder: {'cl6e2kygp002egk55asrs2brz_1_TRUE_COLOR_jpg.rf.2a198a37785242fb6db3ef21c0ffdcad.jpg', 'cl6b5x63r005il4551chxdt93_2_FALSE_COLOR_jpg.rf.8c4fb06b6812031edb1ad781ec14d2b9.jpg', 'cl6kfx47x001tc45578ts0yz6_2_FALSE_COLOR_jpg.rf.5a9501946306fabdad807a6acb61ccbe.jpg', 'cl6kf5xzo000gc4552qc8hhcc_2_FALSE_COLOR_jpg.rf.8fbfb16c6d86076d860904397218acd5.jpg', 'cl6e3enfn003sgk554uim9wo6_1_TRUE_COLOR_jpg.rf.beaf169c01f4596cb24c1c4628ef21f1.jpg', 'cl6b5myi60048l45530d5anq4_1_TRUE_COLOR_jpg.rf.1b9e229b9d66a61c1d9a410fd8ad6f23.jpg', 'cl6e1qges001kgk555z158f33_2_FALSE_COLOR_jpg.rf.479904c9e54c6ba121689341598bf3ed.jpg'}\n",
      "Images in folder but not in DataFrame: set()\n"
     ]
    }
   ],
   "source": [
    "def verify_images(df: pd.DataFrame, column_name: str, folder_path: str):\n",
    "    \"\"\"\n",
    "    Verify consistency between image names in a DataFrame and actual images in a folder.\n",
    "    \"\"\"\n",
    "    p = Path(folder_path)\n",
    "\n",
    "    # Valid image extensions\n",
    "    valid_exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "    # Collect only image file names in the folder\n",
    "    n_names = [n.name for n in p.iterdir() if n.is_file() and n.suffix.lower() in valid_exts]\n",
    "\n",
    "    # Get image names from DataFrame column\n",
    "    img_names = df[column_name].to_list()\n",
    "\n",
    "    # Convert both to sets\n",
    "    set_folder = set(n_names)\n",
    "    set_df = set(img_names)\n",
    "\n",
    "    # Compare\n",
    "    missing_in_folder = set_df - set_folder\n",
    "    missing_in_df = set_folder - set_df\n",
    "\n",
    "    return missing_in_folder, missing_in_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "missing_in_folder, missing_in_df = verify_images(df_images, \"file_name\", \"../dataset/data\")\n",
    "\n",
    "print(\"Images in DataFrame but not in folder:\", missing_in_folder)\n",
    "print(\"Images in folder but not in DataFrame:\", missing_in_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af2b8a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no images without annotations.\n"
     ]
    }
   ],
   "source": [
    "def get_images_without_annotations(images_folder, annotations_file):\n",
    "    \"\"\"\n",
    "    Return a list of images that have no annotations.\n",
    "    \"\"\"\n",
    "    # Load COCO file\n",
    "    with open(annotations_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Get all image IDs that have at least one annotation\n",
    "    annotated_image_ids = {ann[\"image_id\"] for ann in data[\"annotations\"]}\n",
    "\n",
    "    # Map image IDs to file names\n",
    "    id_to_name = {img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]}\n",
    "    annotated_images = {id_to_name[iid] for iid in annotated_image_ids}\n",
    "\n",
    "    # Valid image extensions\n",
    "    valid_exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "    # Get all images in the folder\n",
    "    folder = Path(images_folder)\n",
    "    all_images = {f.name for f in folder.iterdir() if f.is_file() and f.suffix.lower() in valid_exts}\n",
    "\n",
    "    # Find images without annotations\n",
    "    images_without_ann = all_images - annotated_images\n",
    "\n",
    "    return list(images_without_ann)\n",
    "\n",
    "# Example usage\n",
    "result = get_images_without_annotations(\"../dataset\", \"../dataset/data/_annotations.coco.json\")\n",
    "\n",
    "if result:\n",
    "    display(\"Images without annotations are:\", list(result))\n",
    "else:\n",
    "    print(\"There are no images without annotations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01bcf02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique IDs: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er une liste d‚Äôid unique dans les annotations (pandas unique)\n",
    "def unique_ids(df):\n",
    "    \n",
    "    unique_ids = df_annotations['image_id'].unique()\n",
    "\n",
    "    unique_ids_list = unique_ids.tolist()\n",
    "    return unique_ids_list\n",
    "unique_ids_list = unique_ids(df_annotations)\n",
    "\n",
    "print(\"Unique IDs:\", unique_ids_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac074223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, image_id, category_id, bbox, area, segmentation, iscrowd]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "images_without_annotations = df_annotations[~df_annotations['image_id'].isin(unique_ids_list)]\n",
    "print(images_without_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f0b3384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width, Height: (1200, 860)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"../dataset/data/cl6az56oy0003f05554mh92wy_2_FALSE_COLOR_jpg.rf.80849284d2ee075dcfd0d457f4c20b7a.jpg\")\n",
    "#img.show()\n",
    "print(\"Width, Height:\", img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "404e5050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [277, 207, 568.95, 591.79]\n",
       "1        [800, 0, 157.45, 413.38]\n",
       "2        [1062, 96, 58.37, 63.91]\n",
       "3       [452, 442, 410.09, 350.6]\n",
       "4        [0, 163, 336.16, 375.08]\n",
       "                  ...            \n",
       "954      [80, 30, 416.05, 183.75]\n",
       "955      [0, 345, 140.33, 146.25]\n",
       "956       [389, 361, 333, 340.52]\n",
       "957     [510, 270, 222.6, 245.95]\n",
       "958     [645, 519, 87.51, 126.38]\n",
       "Name: bbox, Length: 959, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# √âcrire une fonction qui d√©tecte les valeurs aberrantes pour les annotations (ex : hauteur == 0 et largeur != 0, etc)\n",
    "df_annotations['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4e3289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier annotations:\n",
      "Empty DataFrame\n",
      "Columns: [id, image_id, category_id, bbox, area, segmentation, iscrowd]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def detect_bbox_outliers(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Detect outliers in the 'bbox' column:\n",
    "    - width or height = 0\n",
    "    - width or height < 0\n",
    "    Returns a DataFrame of the outlier rows.\n",
    "    \"\"\"\n",
    "    widths = df['bbox'].apply(lambda x: x[2])\n",
    "    heights = df['bbox'].apply(lambda x: x[3])\n",
    "\n",
    "    condition = (widths <= 0) | (heights <= 0)\n",
    "\n",
    "    outliers = df[condition]\n",
    "\n",
    "    return outliers\n",
    "outlier_annotations = detect_bbox_outliers(df_annotations)\n",
    "\n",
    "print(\"Outlier annotations:\")\n",
    "print(outlier_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delete_images(images_folder_path, images_list):\n",
    "#     \"\"\"\n",
    "#     Delete images from a folder based on a list of image file names.\n",
    "\n",
    "#     Parameters:\n",
    "#     images_folder_path (str or Path): Path to the folder containing images\n",
    "#     images_list (list): List of image file names to delete\n",
    "#     \"\"\"\n",
    "#     # Ensure we have a Path object\n",
    "#     images_folder = Path(images_folder_path)\n",
    "\n",
    "#     # Loop through each image name\n",
    "#     for img_name in images_list:\n",
    "#         img_path = images_folder / img_name  # Full path to the image\n",
    "#         if img_path.exists():               # Check if the file exists\n",
    "#             img_path.unlink()               # Delete the file\n",
    "#             print(f\"Deleted {img_name}\")\n",
    "#         else:\n",
    "#             print(f\"{img_name} not found\")\n",
    "# delete_pics = delete_images(\"../dataset/data\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e8cf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_coco_file(coco_file_path, deleted_images):\n",
    "#     \"\"\"\n",
    "#     Remove entries of deleted images and their annotations from a COCO JSON file.\n",
    "    \n",
    "#     Parameters:\n",
    "#     coco_file_path (str): Path to the COCO JSON file\n",
    "#     deleted_images (list): List of deleted image file names\n",
    "#     \"\"\"\n",
    "#     # Load the COCO JSON file\n",
    "#     with open(coco_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     # Find IDs of deleted images\n",
    "#     deleted_ids = {img[\"id\"] for img in data[\"images\"] if img[\"file_name\"] in deleted_images}\n",
    "\n",
    "#     # Remove deleted images from \"images\"\n",
    "#     data[\"images\"] = [img for img in data[\"images\"] if img[\"id\"] not in deleted_ids]\n",
    "\n",
    "#     # Remove annotations for deleted images\n",
    "#     data[\"annotations\"] = [ann for ann in data[\"annotations\"] if ann[\"image_id\"] not in deleted_ids]\n",
    "\n",
    "#     # Save the updated JSON\n",
    "#     with open(coco_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#     print(\"COCO JSON updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe43b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO JSON updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# # Delete the images\n",
    "# delete_images(\"../dataset\", result)\n",
    "\n",
    "# # Update the COCO JSON using the same list\n",
    "# update_coco_file(\"../dataset/data/_annotations.coco.json\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05b0448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images missing from folder: set()\n",
      "COCO file cleaned successfully!\n"
     ]
    }
   ],
   "source": [
    "def clean_coco(coco_file, images_dir):\n",
    "    images_dir = Path(images_dir)\n",
    "\n",
    "    with open(coco_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    existing_images = {f.name for f in images_dir.iterdir() if f.is_file()}\n",
    "\n",
    "    coco_images = {img[\"file_name\"] for img in data[\"images\"]}\n",
    "\n",
    "    missing = coco_images - existing_images\n",
    "    print(\"Images missing from folder:\", missing)\n",
    "\n",
    "    valid_ids = {img[\"id\"] for img in data[\"images\"] if img[\"file_name\"] in existing_images}\n",
    "    data[\"images\"] = [img for img in data[\"images\"] if img[\"id\"] in valid_ids]\n",
    "    data[\"annotations\"] = [ann for ann in data[\"annotations\"] if ann[\"image_id\"] in valid_ids]\n",
    "\n",
    "    with open(coco_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"COCO file cleaned successfully!\")\n",
    "\n",
    "clean_coco(\"../dataset/data/_annotations.coco.json\", \"../dataset/data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1cee64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 493/493 [373.9ms elapsed, 0s remaining, 1.3K samples/s]      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=8a3b13bc-0308-429b-95b3-b4826cf10a1c\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1281d3e00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ïö‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïë    ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù     ‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ïî‚ïù  ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù\n",
      "‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïë      ‚ñà‚ñà‚ïë   ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
      "‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù        ‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù v1.8.0\n",
      "\n",
      "If you're finding FiftyOne helpful, here's how you can get involved:\n",
      "\n",
      "|\n",
      "|  ‚≠ê‚≠ê‚≠ê Give the project a star on GitHub ‚≠ê‚≠ê‚≠ê\n",
      "|  https://github.com/voxel51/fiftyone\n",
      "|\n",
      "|  üöÄüöÄüöÄ Join the FiftyOne Discord community üöÄüöÄüöÄ\n",
      "|  https://community.voxel51.com/\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=\"../dataset\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    labels_path=\"../dataset/data/_annotations.coco.json\"\n",
    ")\n",
    "session = fo.launch_app(dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
